---
title: "Improving efficiency of HCD tax credit program"
author: "Palak Agarwal"
date: "10-30-2020"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
 
---
# Introduction
The Department of Housing and Community Development (HCD) in Emil City seeks to launch a targeted campaign to encourage homeowners to take advantage of a $5,000 tax credit for home repairs. Typically, only 11% of the eligible homeowners they reach out to take the credit. This analysis attempts to improve the efficiency of HCD's outreach efforts, minimizing outreach to homeowners who are unlikely to take the credit while maximizing outreach to homeowners who are likely to take the credit.    
The method used to maximize this efficiency is by generating a matrix that tells us how likely is the user to accept the credit or not. To make these prediction many variables are used which are related to the likely of taking the credit or not.      

Our analysis uses a binary logistic regression to estimate whether eligible homeowners are likely to take the home repair tax credit based on a number of features. our goal is to create a model that can accurately predict instances of when a homeowner will and will not take the credit. After engineering features to make our predictive model as accurate as possible, we then use a cost-benefit analysis to search for an optimal threshold to limit ‘costly’ errors, or those create the greatest cost to HCD while producing the least benefit to homeowners. Based on our understanding of the credit program, we constructed some stylized facts to inform the cost-benefit analysis:

- For each homeowner predicted to take the credit, HCD will allocate $2,850 for outreach (this figure includes staff and resources to facilitate mailers, phone calls, and information/counseling sessions at the HCD offices).
- Given our new targeting algorithm, we assume 25% of contacted homeowners take the credit.
- The credit costs $5,000 per homeowner which can be used toward home improvement.
- Houses that transacted after taking the credit sold with a $10,000 premium, on average.
- An additional benefit of the credit is that homes surrounding the repaired home see an aggregate premium of $56,000 on average, which HCD would like to consider as a benefit in the cost-benefit analysis.

Initially the file is set up by loading the necessary libraries and the base file.

### Set Up 
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = FALSE)

options(scipen=10000000)

library(tidyverse)
library(kableExtra)
library(caret)
library(knitr) 
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(ggcorrplot)
library(gridExtra)

palette5 <- c("#981FAC","#CB0F8B","#FF006A","#FE4C35","#FE9900")
palette4 <- c("#981FAC","#FF006A","#FE4C35","#FE9900")
palette2 <- c("#981FAC","#FF006A")

house_subsidy <- read.csv("DATA/housingSubsidy.csv")
```

# Data Visualizations

Below are some data visualizations - both of numeric and categorical variables. 

From the below plots the following interpretations can be made :     
- The mean number of contacts prior to this campaign is higher for those who take the credit than those who do not.
- The mean amount of money spent annually on repairs is about the same.
- The mean age of those who take the credit is slightly higher than the mean age of eligible homeowners that do not take the credit.         
- The mean number of times homeowners were contacted within one campaign is higher for those who do not take the credit.
- The mean consumer confidence index and mean consumer price index at the time of the campaign is about the same for those who take the credit and those who do not.
- The mean unemployment rate is higher during more successful campaigns. 
```{r data_vis, warning=FALSE, message=FALSE}
##continuous variables
house_subsidy %>%
  dplyr::select(y,unemploy_rate, spent_on_repairs, age, campaign, 
                previous,cons.price.idx,cons.conf.idx) %>%
  rename("Unemployment Rate" = unemploy_rate, "$ Spent on Repairs" = spent_on_repairs, "Age of Homeowner"=age, "# of contacts"=campaign, "# of previous contacts"=previous, "Cons. Price Index"=cons.price.idx, "Cons. Conf. Index"=cons.conf.idx) %>%
  gather(Variable, value, -y) %>%
  ggplot(aes(y, value, fill=y)) + 
  geom_bar(position = "dodge", stat = "summary", fun = "mean") + 
  facet_wrap(~Variable, scales = "free") +
  scale_fill_manual(values = palette2) +
  labs(x="y", y="Value", 
       title = "Feature associations with the likelihood of taking credit",
       subtitle = "(continous outcomes)") +
  theme(legend.position = "none")
```

## Categorical Variables
Counts of different levels of each categorical variable shown below. These plots are not useful because the data aren't normalized and have count associated with them, not mean.
```{r data_vis2, warning=FALSE, message=FALSE, fig.width= 10,fig.height=12}
# NOT WORKING
house_subsidy$month <-ordered(house_subsidy$month, 
                             levels=c("mar","apr","may","jun","jul","aug","sep","oct","nov","dec"))

house_subsidy$day_of_week <-ordered(house_subsidy$day_of_week, 
                             levels=c("mon","tue","wed","thu","fri"))

## categorical variables
grid.arrange(ncol=3,
house_subsidy %>%
  dplyr::select(y, education) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Education association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45)),
     

## Jobs
house_subsidy %>%
  dplyr::select(y, job) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Job type association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45)),

## Marital
house_subsidy %>%
  dplyr::select(y, marital) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Marital status association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45)),

## taxLien
house_subsidy %>%
  dplyr::select(y, taxLien) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Tax Lien association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45)),

house_subsidy %>%
  dplyr::select(y, mortgage) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Mortgag association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45)),

house_subsidy %>%
  dplyr::select(y, taxbill_in_phl) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Full-time residence in Philly association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45)),

house_subsidy %>%
  dplyr::select(y, contact) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Previous contact association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45)),

# Change order of months
house_subsidy %>%
  dplyr::select(y, month) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Month contacted association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45)),

# Change order of days
house_subsidy %>%
  dplyr::select(y, day_of_week) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Day contacted association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45)),

house_subsidy %>%
  dplyr::select(y, poutcome) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="\n Take Credit", y="Count",
       title = "Outcome of previous campaign association \nwith likelihood of taking credit")+
  theme(axis.text.x = element_text(angle = 45))
)
```

### Feature Engineering
For this part of the model, we used the above plots to identify a few variables that did not make sense to have as they were presented. Below are the modified  features:   
- Employment status - As the status of employment matters more than type of job, we reduced the job category to only 2 categories - employment and unemployed.     
- Seasons - Checking when the user was contacted and identifying the season during that call improved the model. Seasons may impact when people are thinking about house repairs and are more likely to accept the credit during certain seasons.       
- Days of week - Beginning and end of week calls to users might reduce their receptiveness to the marketing campaign when compared to calls during the mid week calls.       
- Education & Age - The specific values of these columns are not as important as the larger brackets they fall under hence we feature engineered them to create smaller categories.     
- Pday - When the consumer was contacted has been made categorical.      
       
Then the new variables were plotted. again these plot aren't useful because data is not normalized.
```{r data, message=FALSE, warning=FALSE, fig.width= 12,fig.height=8}
## Data wrangling
### Employment 

house_subsidy <-
  house_subsidy %>%
  mutate(Employment = ifelse(house_subsidy$job == "blue-collar"|house_subsidy$job == "services"|house_subsidy$job =="admin."|house_subsidy$job =="entrepreneur"|
                               house_subsidy$job =="self-employed"|house_subsidy$job =="technician"|house_subsidy$job =="management"|
                               house_subsidy$job =="housemaid",1,0))
### Pdays 
house_subsidy <-
  house_subsidy %>%
  mutate(Pdays_group = case_when(
    pdays >= 1 & pdays <= 7 ~ "In a week",
    pdays >= 8 & pdays <= 14  ~ "Second week",
    pdays >= 15 & pdays <= 21  ~ "Third week",
    pdays >= 22 & age < 999  ~ "After a month",
    pdays >= 999   ~ "Never contacted"))

### Age
house_subsidy <-
  house_subsidy %>%
  mutate(Age_group = case_when(
    age < 18 ~ "Less than 18",
    age >= 18 & age < 25  ~ "18-25",
    age >= 25 & age < 35  ~ "25-35",
    age >= 35 & age <= 50  ~ "35-50",
    age >= 50 & age < 65   ~ "50-65",
    age >= 65   ~ "Above 65"))

### Education
house_subsidy <-
  house_subsidy %>%
  mutate(Education_group = case_when(
    education == "basic.9y" |education == "basic.6y" | education == "basic.4y" ~ "Basics",
    education == "high.school"  ~ "High School",
    education == "university.degree" |education == "professional.course"  ~ "College",
    education == "unknown" |education == "illiterate"  ~ "Illiterate"))

### Seasons
house_subsidy <-
  house_subsidy %>%
  mutate(Season = case_when(
    month == "dec" |month == "jan" | month == "feb" ~ "Winter",
    month == "mar" |month == "apr" | month == "may" ~ "Spring",
    month == "jun" |month == "jul" | month == "aug" ~ "Summer",
    month == "sep" |month == "oct" | month == "nov" ~ "Fall"))

### Day
house_subsidy <-
  house_subsidy %>%
  mutate(Day = case_when(
    day_of_week == "mon" |day_of_week == "fri" ~ "Busy",
    day_of_week == "tue" |day_of_week == "wed" | day_of_week == "thu" ~ "Non-busy"))


grid.arrange (ncol=3,
house_subsidy %>%
  dplyr::select(y, Employment) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="Take Credit", y="Count",
       title = "Employment status association \nwith likelihood of taking credit"),

house_subsidy %>%
  dplyr::select(y, Age_group) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="Take Credit", y="Count",
       title = "Age group association \nwith likelihood of taking credit"),

house_subsidy %>%
  dplyr::select(y, Education_group) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="Take Credit", y="Count",
       title = "Education group association \nwith likelihood of taking credit"),

house_subsidy %>%
  dplyr::select(y, Season) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="Take Credit", y="Count",
       title = "Season contacted association \nwith likelihood of taking credit"),

house_subsidy %>%
  dplyr::select(y, Day) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="Take Credit", y="Count",
       title = "Day contacted association \nwith likelihood of taking credit"),

house_subsidy %>%
  dplyr::select(y, Pdays_group) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
  geom_bar(position = "dodge", stat="identity") +
  facet_wrap(~Variable, scales="free") +
  scale_fill_manual(values = palette2) +
  labs(x="Take Credit", y="Count",
       title = "Time associated with contacted association \nwith likelihood of taking credit"))

```

## Correlation
This plot shows that none of our numeric variables are strongly correlated with whether or not an eligible homeowner takes the credit. 

The plot suggests that some of our numeric variables may be colinear. The unemployment rate at time of contact is strongly positively correlated with the inflation rate at time of contact. The inflation rate at time of contact is also strongly positively correlated with the amount of money spent annually on repairs.
```{r correlation, message=FALSE, warning=FALSE}

numericVars1 <- 
  select_if(house_subsidy, is.numeric) %>% na.omit() %>%
  dplyr::select(age, unemploy_rate, cons.price.idx, cons.conf.idx, inflation_rate, spent_on_repairs,y_numeric)

ggcorrplot(
  round(cor(numericVars1), 1), 
  p.mat = cor_pmat(numericVars1),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
  labs(title = "Correlation across Characteristics") 


```

# Compare Models    
     
There are two models used in the regression below. One is the **Kitchen Sink Model** and the other is the **Feature Engineered Model.** Our model with feature engineering is not better than the "kitchen sink" model. Both have low sensitivities (true positive rate).         
           
Confusion Matrix :                 
The confusion metrics as you can see has 4 possible outputs - combinations of 0 and 1.
1.True positive means we predicted they would take the credit and they took it. However, our research suggests that only 25% of our true positives will actually take the credit. (1 - observed, 1 - predicted)             
2.True negative means we predicted they would not take the credit and they didn't. (0 - observed, 0 - predicted)          
3.False positive means we predicted they would take the credit, but they did not. (0 - observed, 1 - predicted)               
4.False negative means we predicted they would not take the credit, but they did. (0 - observed, 1 - predicted)                   
                  
A very predictive regression would show clustering of 0 (don't take the credit) around 0 and clustering of 1 (do take the credit) around 1. Neither model shows clustering around 1, indicating that these models have poor sensitivity(true positive rate).
```{r regs, message=FALSE, warning=FALSE}
#house_subsidy <- rename(house_subsidy,y.numeric=y_numeric)

set.seed(3456)
trainIndex <- createDataPartition(house_subsidy$y, p = .65, 
                                  y = paste(house_subsidy$Education_group,house_subsidy$Age_group,house_subsidy$Season,house_subsidy$Employment,house_subsidy$taxLien),
                                  list = FALSE,
                                  times = 1)
housingTrain <- house_subsidy[ trainIndex,]
housingTest  <- house_subsidy[-trainIndex,]

## Regression
### Kichen Sink Model

kitchensink <- glm(y_numeric ~ .,
                    data=housingTrain %>% 
                      dplyr::select(-X, -Season, -Education_group,-Age_group,-Employment, -Day, -y, -Pdays_group),
                    family="binomial" (link="logit"))

#summary(kitchensink)
  
housingModel <- glm(y_numeric ~ .,
                    data=housingTrain %>% 
                      dplyr::select(-y,-X, -contact,-month,-day_of_week,-poutcome,-Age_group, 
                                 -education, -job),
                    family="binomial" (link="logit"))

#summary(housingModel)

## Adding Coefficients
#x <- housingModel$coefficients
#exp(x)


## Fit metrics
# pR2(kitchensink)
pR2(housingModel)

## Prediction
testProbs <- data.frame(Outcome = as.factor(housingTest$y_numeric),
                        Probs = predict(housingModel, housingTest, type= "response"))

testProbs$Probs <- ifelse(is.na(testProbs$Probs), 0.1043699, testProbs$Probs) 

testProbskitchensink <- data.frame(Outcome = as.factor(housingTest$y_numeric),
                        Probs = predict(kitchensink, housingTest, type= "response"))

#Here we want more of a hump in the bottom plot around 1 to indicate that the reg is predictive
ggplot(testProbskitchensink, aes(x = Probs, fill = as.factor(Outcome))) + 
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) +
  labs(x = "Click", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome",
       subtitle = "Kitchen Sink Model") +
  theme(strip.text.x = element_text(size = 18),
        legend.position = "none")

ggplot(testProbs, aes(x = Probs, fill = as.factor(Outcome))) + 
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) +
  labs(x = "Click", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome",
       subtitle = "Model with Feature Engineering") +
  theme(strip.text.x = element_text(size = 18),
        legend.position = "none")

## Confusion matrix
### Might want to change this threshold, here a probability >50% if being predicted as takes credit
testProbskitchensink <- 
  testProbskitchensink %>%
  mutate(predOutcome  = as.factor(ifelse(testProbskitchensink$Probs > 0.5 , 1, 0)))

caret::confusionMatrix(testProbskitchensink$predOutcome, testProbskitchensink$Outcome, 
                       positive = "1")

testProbs <- 
  testProbs %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs$Probs >= 0.5 , 1, 0)))

caret::confusionMatrix(testProbs$predOutcome, testProbs$Outcome, 
                       positive = "1")
```

## Cross Validation
We tested both models using cross-validation. again, shows low sensitivity (true positive) and high specificity (true negative) rates for both models. The same can be seen on the plots that show the area under the ROC curve, sensitivity, and specificity. If model were generalizable and had a good goodness of fit, would expect all of these plots to be clustered around mean. As its visible, the specificity and the ROC of the models are good and can be a measure of goodness of fit but the variables need to be feature engineered better to get better sensitivity values.
```{r cv, message=FALSE, warning=FALSE, fig.width= 10, fig.height=4}


## Cross validation
ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)

cvFitkitchensink <-train(y ~ .,
               data=house_subsidy %>% 
                 dplyr::select(-X, -y_numeric, -Season, -Education_group,-Age_group,-Employment, -Day, -Pdays_group) %>%
                 dplyr::mutate(y = ifelse(y=="yes","c1.yes","c2.no")),
               method="glm", family="binomial",
               metric="ROC", trControl = ctrl)
  
cvFitkitchensink

cvFit <- train(y ~ .,
                data=house_subsidy %>% 
                  dplyr::select(-y_numeric,-X, -contact,-month,-day_of_week,-poutcome,-Age_group, 
                                 -education, -job, -Pdays_group) %>%
                  dplyr::mutate(y = ifelse(y=="yes","c1.yes","c2.no")), 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)


cvFit

## Goodness metrics
grid.arrange(ncol = 2,

  dplyr::select(cvFitkitchensink$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFitkitchensink$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
  geom_histogram(bins=35, fill = "#FF006A") +
  facet_wrap(~metric) +
  geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics \n Kitchen Sink Model",
       subtitle = "Across-fold mean reprented as dotted lines"),


  dplyr::select(cvFit$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
  geom_histogram(bins=35, fill = "#FF006A") +
  facet_wrap(~metric) +
  geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics \n Feature Engineered Model",
       subtitle = "Across-fold mean reprented as dotted lines"))
```


### Receiver Operating Characteristic Curve
The Receiver Operating Characteristic Curve or ROC Curve is useful because it visualizes trade-offs for two important confusion metrics, while also providing a single goodness of fit indicator. When increase true positives, also increase false positives, that means HCD will waste money on marketing more. For example, according to the ROC Curve, a threshold that predicts taking the credit correctly 50% of the time, will predict taking the credit incorrectly 10% of the time.    
           
The AUC is an indicator of goodness of fit. A 100% is overfit, 50% would be coin flip, and anything between the two is a useful fit. The AUC of our model is 72.24% which indicates that our model predicts reasonably well and it is a goodness of fit metric.
```{r ROC, warning=FALSE, message=FALSE}
## ROC curve
# This us a goodness of fit measure, 1 would be a perfect fit, .5 is a coin toss
auc(testProbs$Outcome, testProbs$Probs)

ggplot(testProbs, aes(d = as.numeric(testProbs$Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - Model with Feature Engineering")
```

# Cost/Benefit Analysis
For the cost and benefit table was split into HCD expenditures and increases to house values. As the HCD is a non profit and has no direct relation to the increase in the costing of the house, we felt is was apt to split the two costing. Below is the explanation of how we split the costing among the possible outcomes.        
                    
- True negative: no HCD expenditure, no housing increases, **Count*0**

- True positive: HCD spends $2850 on marketing for all true positives and $5000 on tax credit for the 25% that actually take it, equation is **(Count*2850)+(Count*.25*5000)**; benefit is $10000 increase in home value plus $56000 increase in value of surrounding homes, equation is **(.25*Count*10000)+(.25*Count*56000)**

- False negative: HCD did not spend money on marketing, but homeowner still took credit. Since we are analyzing impact of marketing campaign, we zero this out. Equation for both is **Count*0**

- False positive: HCD spends money on marketing, equation is **count*2850**. No increase in values to homes. Equation is **Count*0**

```{r cb_analysis, message=FALSE, warning=FALSE}
## Cost benefit
cost_benefit_table <-
  testProbs %>%
  count(predOutcome, Outcome) %>%
  summarize(True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                True_Positive = sum(n[predOutcome==1 & Outcome==1]),
                False_Negative = sum(n[predOutcome==0 & Outcome==1]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0])) %>%
  gather(Variable, Count) %>%
  mutate(HCD_Expenditure =
           case_when(Variable == "True_Negative" ~ Count*0,
                Variable == "True_Positive" ~ (Count*2850)+(Count*5000*.25),
                Variable == "False_Negative" ~ Count*0,
                Variable == "False_Positive" ~ (Count*2850))) %>%
  mutate(Home_Value_Added =
           case_when(Variable == "True_Negative" ~ Count*0,
                Variable == "True_Positive" ~ (Count*.25*10000)+(Count*.25*56000),
                Variable == "False_Negative" ~ Count*0,
                Variable == "False_Positive" ~ -(Count*0))) %>%
  mutate(Number_Credits =
           case_when(Variable == "True_Negative" ~ Count*0,
                     Variable == "True_Positive" ~ Count*.25,
                     Variable == "False_Negative" ~ Count*0,
                     Variable == "False_Positive" ~ Count*0)) %>%
  bind_cols(data.frame(Description = c(
    "We correctly predicted not taking credit",
    "We correctly predicted taking credit",
    "We predicted would not take credit and customer took credit",
    "We predicted customer would take credit and customer did not take credit")))

kable(cost_benefit_table,
      caption = "Cost/Benefit Table") %>% kable_styling()
```

## Comparing Thresholds
### Confusion Metric Plots
Next we move on to plotting the confusion metrics for all thresholds from 1% to a 100%. To do this we use a function called **iteratethreshold** which saves the value of HCD expenditure, value added to the homes and the number of credits for each threshold.    
In the below plots you can see that for HCD expenditure by confusion metric, the true negative is not visible asits below the false negative because it is also 0 and are overlaid one top of other. The plot also shows that the HCD expenditure on false positives decreases steeply as threshold increases until a threshold of about 12.5%.     
For added value to homes by confusion metric plot, value added would be highest at a threshold of 0. However, a lot of money would be wasted on marketing, as seen in the previous plot. No other confusion metric is shown as no other metric sees a change in home values.

```{r confmetrics, message=FALSE, warning=FALSE}

## Optimise threshold
iterateThresholds <- function(data) {
  x = .01
  all_prediction <- data.frame()
  while (x <= 1) {
    
    this_prediction <-
      testProbs %>%
      mutate(predOutcome = ifelse(Probs > x, 1, 0)) %>%
      count(predOutcome, Outcome) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                True_Positive = sum(n[predOutcome==1 & Outcome==1]),
                False_Negative = sum(n[predOutcome==0 & Outcome==1]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0])) %>%
      gather(Variable, Count) %>%
      mutate(HCD_Expenditure =
             case_when(Variable == "True_Negative" ~ Count*0,
                Variable == "True_Positive" ~ (Count*2850)+(Count*5000*.25),
                Variable == "False_Negative" ~ Count*0,
                Variable == "False_Positive" ~ (Count*2850)), 
            Threshold = x,
            Number_Credits =
               ifelse(Variable == "True_Negative", Count * 0,
               ifelse(Variable == "True_Positive", (Count*.25),
               ifelse(Variable == "False_Negative", Count*0,
               ifelse(Variable == "False_Positive", Count*0,0)))),
            Home_Value_Added =
           case_when(Variable == "True_Negative" ~ Count*0,
                Variable == "True_Positive" ~ (Count*10000*.25)+(Count*56000*.25),
                Variable == "False_Negative" ~ Count*0,
                Variable == "False_Positive" ~ -(Count*0)),
           Revenue =
           case_when(Variable == "True_Negative" ~ Count*0,
                Variable == "True_Positive" ~ ((Count*.25*10000) + (Count*.25*56000)-(Count*2850)-(Count*.25*5000)),
                Variable == "False_Negative" ~ Count*0,
                Variable == "False_Positive" ~ -(Count*2850)))
    
    all_prediction <- rbind(all_prediction, this_prediction)
    x <- x + .01
  }
  return(all_prediction)
}

whichThreshold <- iterateThresholds(testProbs)


## Plot confusion metrics for each threshold
whichThreshold %>%
  ggplot(.,aes(Threshold, HCD_Expenditure, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette5[c(5, 1:3)]) +    
  labs(title = "HCD Expenditure by confusion metric type and threshold",
       y = "Expenditure") +
  #plotTheme() +
  guides(colour=guide_legend(title = "Confusion Metrics")) 

whichThreshold %>% filter(Variable == "True_Positive") %>%
  ggplot(.,aes(Threshold, Home_Value_Added, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = "#FF006A") +    
  labs(title = "Value added to homes by true positive metric and threshold",
       y = "Value added") +
  #plotTheme() +
  guides(colour=guide_legend(title = "Confusion Metric")) 
```


### Threshold Plots
- First plot shows both HCD expenditures and value added to homes for each threshold. The goal is to minimize HCD expenditures while maximizing value added to homes. HCD being a government agency it has no profit gain calculation of its own and works for the betterment of the public. 
- The second plot combines these terms, taking the value added to homes and subtracting HCD expenditures for each threshold. This shows that the optimal threshold is about .2, meaning any homeowner with a 20% probability of taking the credit is considered a "positive" case. This plot also shows that at thresholds below about 10%, HCD spends more money than is gained by adding value to houses
- The third plot shows the number of tax credits claimed at each threshold.This shows that the highest number of tax credits would be claimed with a very low threshold, meaning almost every eligible homeowner would receive marketing materials. However, the previous plots show that this would cost too much money compared to the financial benefits to the homeowners
- The final table shows the HCD expenditures and value added to homes for our optimal threshold of 20% and a default threshold of 50%. The 50% threshold saves HCD money in marketing, but the value added to homes is also quite low. At a 20% threshold, HCD spends $527,800 in marketing and tax credits, which lead to a $1,023,000 increase in the value of the homes
```{r thresholds, message=FALSE, warning=FALSE}

whichThreshold_hcd <- 
  whichThreshold %>% 
  group_by(Threshold) %>% na.omit() %>%
  summarize(HCD_Expenditure = sum(HCD_Expenditure),
            Home_Value_Added = sum(Home_Value_Added))

ggplot(whichThreshold_hcd)+
  geom_line(aes(x = Threshold, y = HCD_Expenditure, color = "HCD_Expenditure"))+
  geom_line(aes(x = Threshold, y = Home_Value_Added, color = "Home_Value_Added"))+
  labs(title = "Model HCD expense and Home value addition By Threshold \nFor Test Sample", y = "Dollars")+theme(legend.title = element_blank())

whichThreshold_revenue <- 
  whichThreshold %>% 
  group_by(Threshold) %>% na.omit() %>%
  summarize(Revenue = sum(Revenue))

ggplot(whichThreshold_revenue)+
  geom_line(aes(x = Threshold, y = Revenue))+
  geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -Revenue)[1,1]))+
  labs(title = "Home Value Aded Minus HCD Expenditures By Threshold For Test Sample",
       subtitle = "Vertical Line Denotes Optimal Threshold")

whichThreshold_credits <- 
  whichThreshold %>% 
  group_by(Threshold) %>% 
  summarize(Number_Credits= sum(Number_Credits))

ggplot(whichThreshold_credits)+
  geom_line(aes(x = Threshold, y = Number_Credits))+
  labs(title = "Model Number of Credits By Threshold For Test Sample")



# Optimal Threshold
optimum_threshold <- pull(arrange(whichThreshold_revenue, -Revenue)[1,1])

opt <- 
  whichThreshold %>% 
  group_by(Threshold) %>% 
  summarize(HCD_Expenditure = sum(HCD_Expenditure),
            Home_Value_Added = sum(Home_Value_Added),
            Number_Credits= sum(Number_Credits)) %>%
  filter(Threshold == optimum_threshold)

fifty_thresh <-
  whichThreshold %>% 
  group_by(Threshold) %>% 
  summarize(HCD_Expenditure = sum(HCD_Expenditure),
            Home_Value_Added = sum(Home_Value_Added),
            Number_Credits= sum(Number_Credits)) %>%
  filter(Threshold > .499 & Threshold < .51)

final <- data.frame(rbind(opt, fifty_thresh))

kable(final,
      caption = "Optimum Threshold and 50% Threshold") %>% kable_styling()

```

# Conclusion    

In general, I would recommend putting this model into production as it will benefit the highest number of households and generate the highest amount of direct and indirect benefits to the Emil City community but it would need smarter features and more demographic data. The main issue is that the sensitivity is very low, meaning that the model does not do a good job of predicting actual positive credit acceptances. This is likely because there are so few “yes” outcomes in the underlying data.    
In order to improve the model, I would recommend working with more data to improve the model, or engineer better features for predicting. To ensure that the marketing materials resulted in a better response rate, I would first test my improved method as a pilot program. This could serve as a test case to get a sense of whether the new method is working, or if it needs to be further improved before being implemented at a larger scale. In cases where there are limited resources available, it may be better to be cautious (thus using a pilot approach) before implementing an entirely new and untested method.